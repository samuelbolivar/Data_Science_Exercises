{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DAT19 Class 5 - Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation with KNN\n",
    "\n",
    "Part of the big step with this lab is understanding general sklearn syntax. Each family of classification algorithms have various knobs and levers to tune it appropriately but there is a general overall structure to these models that will help you as you move forward.\n",
    "1. All models need to be trained. Sklearn models have a `.fit` method for doing so.\n",
    "2. We need to use the model to make a guess. the `.predict` method takes data and returns the model's guess for the value. Stipulations around this pertain to the specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we imported our data from the UCI Machine Learning repository using pandas. Scikit-learn also includes some well-known datasets. So, for convenience, we will import the iris data set from sklearn this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the datasets load the iris data into a variable called iris\n",
    "from sklearn import datasets\n",
    "\n",
    "sk_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sk_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
      "      dtype='|S10'), 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']}\n"
     ]
    }
   ],
   "source": [
    "print sk_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Bunch in module sklearn.datasets.base object:\n",
      "\n",
      "class Bunch(__builtin__.dict)\n",
      " |  Container object for datasets\n",
      " |  \n",
      " |  Dictionary-like object that exposes its keys as attributes.\n",
      " |  \n",
      " |  >>> b = Bunch(a=1, b=2)\n",
      " |  >>> b['b']\n",
      " |  2\n",
      " |  >>> b.b\n",
      " |  2\n",
      " |  >>> b.a = 3\n",
      " |  >>> b['a']\n",
      " |  3\n",
      " |  >>> b.c = 6\n",
      " |  >>> b['c']\n",
      " |  6\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Bunch\n",
      " |      __builtin__.dict\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattr__(self, key)\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |  \n",
      " |  __setattr__(self, key, value)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from __builtin__.dict:\n",
      " |  \n",
      " |  __cmp__(...)\n",
      " |      x.__cmp__(y) <==> cmp(x,y)\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      D.__contains__(k) -> True if D has a key k, else False\n",
      " |  \n",
      " |  __delitem__(...)\n",
      " |      x.__delitem__(y) <==> del x[y]\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      x.__iter__() <==> iter(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __setitem__(...)\n",
      " |      x.__setitem__(i, y) <==> x[i]=y\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  fromkeys(...)\n",
      " |      dict.fromkeys(S[,v]) -> New dict with keys from S and values equal to v.\n",
      " |      v defaults to None.\n",
      " |  \n",
      " |  get(...)\n",
      " |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      " |  \n",
      " |  has_key(...)\n",
      " |      D.has_key(k) -> True if D has a key k, else False\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> list of D's (key, value) pairs, as 2-tuples\n",
      " |  \n",
      " |  iteritems(...)\n",
      " |      D.iteritems() -> an iterator over the (key, value) items of D\n",
      " |  \n",
      " |  iterkeys(...)\n",
      " |      D.iterkeys() -> an iterator over the keys of D\n",
      " |  \n",
      " |  itervalues(...)\n",
      " |      D.itervalues() -> an iterator over the values of D\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> list of D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      " |  \n",
      " |  popitem(...)\n",
      " |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
      " |      2-tuple; but raise KeyError if D is empty.\n",
      " |  \n",
      " |  setdefault(...)\n",
      " |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      " |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F: D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> list of D's values\n",
      " |  \n",
      " |  viewitems(...)\n",
      " |      D.viewitems() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  viewkeys(...)\n",
      " |      D.viewkeys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  viewvalues(...)\n",
      " |      D.viewvalues() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from __builtin__.dict:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sk_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting:\n",
    "```Container object for datasets: dictionary-like object that exposes its keys as attributes.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print sk_iris['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_iris['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remember last time when we put all the features in a matrix and the labels (what we are trying to predict) into a vector?\n",
    "\n",
    "Let's re-assign the data to standard named variables. Sklearn makes this very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sk_iris.data\n",
    "y = sk_iris.target\n",
    "Names = sk_iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "print type(X)\n",
    "print np.shape(X)\n",
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(3,)\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print type(Names)\n",
    "print np.shape(Names)\n",
    "print Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we get into cross validation! The first step is to split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is there a function to do that in sklearn?\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = range(150) #What data structure is ind? What is its shape?\n",
    "np.random.shuffle(ind) #Why must we randomly shuffle the (indices for the) training data before splitting it?\n",
    "test_ind = ind[:150/5] #Would this work if 20% of the number of records were not an integer?\n",
    "train_ind = ind[150/5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 17, 82, 149, 88, 140, 134, 55, 19, 6, 148, 78, 71, 146, 67, 145, 96, 46, 11, 133, 94, 109, 126, 103, 85, 15, 20, 51, 45, 47]\n",
      "length of test index is 30\n",
      "\n",
      "\n",
      "[52, 118, 61, 114, 60, 33, 29, 3, 27, 49, 95, 115, 16, 147, 42, 87, 89, 99, 128, 9, 138, 113, 111, 31, 141, 21, 130, 54, 24, 40, 92, 120, 2, 7, 41, 59, 121, 83, 18, 0, 98, 139, 39, 64, 68, 22, 106, 80, 131, 75, 13, 57, 37, 30, 112, 53, 124, 32, 34, 123, 116, 58, 73, 77, 104, 93, 142, 117, 125, 143, 129, 38, 84, 100, 62, 70, 1, 50, 108, 76, 102, 74, 136, 66, 91, 65, 72, 97, 56, 122, 43, 137, 79, 35, 119, 4, 135, 105, 12, 69, 26, 110, 144, 10, 86, 127, 81, 23, 36, 48, 107, 63, 8, 28, 90, 132, 14, 101, 5, 25]\n",
      "length of training index is 120\n"
     ]
    }
   ],
   "source": [
    "print test_ind\n",
    "print 'length of test index is ' + str(len(test_ind))\n",
    "print '\\n'\n",
    "print train_ind\n",
    "print 'length of training index is ' + str(len(train_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for ind in test_ind:\n",
    "    X_test.append(X[ind])\n",
    "    y_test.append(y[ind])\n",
    "    \n",
    "for ind in train_ind:\n",
    "    X_train.append(X[ind])\n",
    "    y_train.append(y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute, what's going on with this syntax above? Does anything about it look unusual to you?\n",
    "Let's take a look at the [function documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) and the [user guide](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<type 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5.9,  3. ,  5.1,  1.8],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2]]), array([[ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5. ,  3.4,  1.6,  0.4]]), array([2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "        1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0,\n",
       "        2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
       "        0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2,\n",
       "        0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 2, 1, 2, 0]), array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "        0, 2, 0, 0, 1, 1, 0])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_return = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "print len(tts_return)\n",
    "print type(tts_return)\n",
    "tts_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5.9,  3. ,  5.1,  1.8],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0,\n",
       "       2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
       "       0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2,\n",
       "       0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "       0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5. ,  3.4,  1.6,  0.4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick Question: How can we double check that got the number of features and labels that we expected?\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll train our model and use it to make predictions, following the steps we outlined last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train KNN classifier defined function on the train data\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out how good our model is. The traditional score is what percentage of my labels did I correctly identify. This is called **accuracy** or **precision**. There are other types of statistical scores but we will start here. We'll ask our model to predict what the labels for our test set are, then generate a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "       0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = myknn.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct: 29\n",
      "Score: 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for a,b in zip(y_test,myknn.predict(X_test)):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print \"Number correct:\",correct\n",
    "print \"Score:\",float(correct)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy enough. Sklearn also has an easy method for generating a score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also has a way of showing more information about the prediction. Here, we're using sklearn.metrics.classification_report to generate a more informative picture. The wikipedia pages for recall, f1-score, and support are also informative if you're looking to understand more.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        11\n",
      " versicolor       0.93      1.00      0.96        13\n",
      "  virginica       1.00      0.83      0.91         6\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([sk_iris['target_names'][label] for label in y_test], \n",
    "                                    [sk_iris['target_names'][label] for label in myknn.predict(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "#### 1. How does the model perform as we increase the number of neighbors?  To answer this, plot the score as a function of the number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11472f590>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAH4CAYAAAALn5onAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwD/a7g7l2KfXYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11467f2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of the various numbers of neighbors to use to build models\n",
    "# Create training and test sets\n",
    "# Iterate through that list and for each number of neighbors:\n",
    "#    Build a KNN model\n",
    "#    Evaluate it\n",
    "#    Record the score with the number of neighbors for that model\n",
    "# Plot results\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "n_neighbors = range(1, 51)\n",
    "\n",
    "scores = []\n",
    "for n in n_neighbors:\n",
    "    clf = KNeighborsClassifier(n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "knn_scores_df = pd.DataFrame(scores, columns=[\"Accuracy\"])\n",
    "ax = knn_scores_df.plot(figsize=(10,8), title=\"N-Neighbor Parameter Accuracy\")\n",
    "ax.set_xlabel(\"N-Neighbors\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Do different train/test splits affect our score (accuracy)? How much do the scores vary each time you shuffle and split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1 75/25\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89333333333333331"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2 50/50\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.50, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88571428571428568"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3 30/70\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.70, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91111111111111109"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 4 90/10\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.90, random_state=0)\n",
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
